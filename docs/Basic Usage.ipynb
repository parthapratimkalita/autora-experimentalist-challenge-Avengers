{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": "# Basic Usage"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What's in this notebook?\n",
    "In this notebook, we will demonstrate how to use AutoRA to perform a simple discovery experiment. We will use a synthetic experiment runner and a simple theorist to demonstrate the basic functionality of AutoRA. We will also show how to set up a custom experimentalist to perform the discovery experiment.\n",
    "\n",
    "The synthetic experiment runner we will use is a task-switching experiment. In this experiment, participants are asked to switch between two tasks. The experiment runner generates data based on a simple linear model with some added noise.\n",
    "\n",
    "The theorist we will use is a polynomial regressor. The polynomial regressor fits a polynomial function to the data.\n",
    "\n",
    "The experimentalist we will use is a random experimentalist. The random experimentalist samples experiment conditions randomly from a pool of experiment conditions.\n",
    "\n",
    "The discovery experiment will consist of the following steps:\n",
    "1. We will start with a randomly sampled data set.\n",
    "2. We will fit a model to the data.\n",
    "3. We will evaluate the performance of the model on a validation set.\n",
    "4. We will sample new experiment conditions.\n",
    "5. We will obtain observations for the new experiment conditions.\n",
    "6. We will repeat steps 2-5 for a number of cycles.\n",
    "\n",
    "At the end of the discovery experiment, we will plot the mean squared error (MSE) of the model on the validation set over the cycles.\n",
    "\n",
    "We will also show how to set up a custom experimentalist to perform the discovery experiment. The custom experimentalist will sample experiment conditions based on the predictions of the models fitted by the theorist.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Installation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%capture\n",
    "!pip install autora\n",
    "!pip install autora[all-theorists]\n",
    "!pip install autora[all-experimentalists]\n",
    "!pip install git+https://github.com/musslick/autora-experimentalist-challenge"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Required Libraries"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# autora state\n",
    "from autora.state import State, on_state, Delta, VariableCollection\n",
    "\n",
    "# experiment_runner\n",
    "from autora.experiment_runner.synthetic.neuroscience.task_switching import task_switching\n",
    "\n",
    "# experimentalist\n",
    "from autora.experimentalist.grid import grid_pool\n",
    "from autora.experimentalist.random import random_pool, random_sample\n",
    "\n",
    "# theorist\n",
    "from autora.theorist.bms import BMSRegressor\n",
    "\n",
    "# sklearn\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import linear_model\n",
    "\n",
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup AutoRA"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class PolynomialRegressor:\n",
    "    \"\"\"\n",
    "    This theorist fits a polynomial function to the data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degree: int = 3):\n",
    "      self.poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "      self.model = LinearRegression()\n",
    "\n",
    "    def fit(self, x, y):\n",
    "      features = self.poly.fit_transform(x, y)\n",
    "      self.model.fit(features, y)\n",
    "      return self\n",
    "\n",
    "    def predict(self, x):\n",
    "      features = self.poly.fit_transform(x)\n",
    "      return self.model.predict(features)\n",
    "\n",
    "    def print_eqn(self):\n",
    "        # Extract the coefficients and intercept\n",
    "        coeffs = self.model.coef_\n",
    "        intercept = self.model.intercept_\n",
    "\n",
    "        # Handle multi-output case by iterating over each output's coefficients and intercept\n",
    "        if coeffs.ndim > 1:\n",
    "            for idx in range(coeffs.shape[0]):\n",
    "                equation = f\"y{idx+1} = {intercept[idx]:.3f}\"\n",
    "                feature_names = self.poly.get_feature_names_out()\n",
    "                for coef, feature in zip(coeffs[idx], feature_names):\n",
    "                    equation += f\" + ({coef:.3f}) * {feature}\"\n",
    "                print(equation)\n",
    "        else:\n",
    "            equation = f\"y = {intercept:.3f}\"\n",
    "            feature_names = self.poly.get_feature_names_out()\n",
    "            for coef, feature in zip(coeffs, feature_names):\n",
    "                equation += f\" + ({coef:.3f}) * {feature}\"\n",
    "            print(equation)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from autora.experimentalist.autora_experimentalist_example import sample\n",
    "\n",
    "\n",
    "# SET UP STATE\n",
    "# Here, we use a non-standard State to be able to use a multiple models\n",
    "@dataclass(frozen=True)\n",
    "class CustomState(State):\n",
    "    variables: Optional[VariableCollection] = field(\n",
    "        default=None, metadata={\"delta\": \"replace\"}\n",
    "    )\n",
    "    conditions: Optional[pd.DataFrame] = field(\n",
    "        default=None, metadata={\"delta\": \"replace\", \"converter\": pd.DataFrame}\n",
    "    )\n",
    "    experiment_data: Optional[pd.DataFrame] = field(\n",
    "        default=None, metadata={\"delta\": \"extend\", \"converter\": pd.DataFrame}\n",
    "    )\n",
    "    models_bms: List[BaseEstimator] = field(\n",
    "        default_factory=list,\n",
    "        metadata={\"delta\": \"extend\"},\n",
    "    )\n",
    "    models_lr: List[BaseEstimator] = field(\n",
    "        default_factory=list,\n",
    "        metadata={\"delta\": \"extend\"},\n",
    "    )\n",
    "    models_polyr: List[BaseEstimator] = field(\n",
    "        default_factory=list,\n",
    "        metadata={\"delta\": \"extend\"},\n",
    "    )\n",
    "    \n",
    "# state wrapper for all theorists\n",
    "@on_state()\n",
    "def theorists_on_state(experiment_data, variables, bms_epochs):\n",
    "\n",
    "  # extract conditions X and observations y from experiment data\n",
    "  ivs = [iv.name for iv in variables.independent_variables]\n",
    "  dvs = [dv.name for dv in variables.dependent_variables]\n",
    "  X = experiment_data[ivs]\n",
    "  y = experiment_data[dvs]\n",
    "\n",
    "  # initialize and fit theorists\n",
    "  theorist_bms = BMSRegressor(epochs=bms_epochs)\n",
    "  theorist_polyr = PolynomialRegressor()\n",
    "  theorist_lr = linear_model.LinearRegression()\n",
    "\n",
    "  return Delta(models_bms = [theorist_bms.fit(X, y)],\n",
    "               models_lr=[theorist_lr.fit(X, y)],\n",
    "               models_polyr=[theorist_polyr.fit(X, y)])\n",
    "\n",
    "\n",
    "# state wrapper for grid pooler experimentalist (generates a grid of experiment conditions)\n",
    "@on_state()\n",
    "def grid_pool_on_state(variables):\n",
    "  return Delta(conditions=grid_pool(variables))\n",
    "\n",
    "# state wrapper for random pooler experimentalist (generates a pool of experiment conditions)\n",
    "@on_state()\n",
    "def random_pool_on_state(variables, num_samples, random_state=None):\n",
    "  return Delta(conditions=random_pool(variables, num_samples, random_state))\n",
    "\n",
    "# state wrapper for random experimentalist (samples experiment conditions from a set of conditions)\n",
    "@on_state()\n",
    "def random_sample_on_state(conditions, all_conditions, num_samples, random_state=None):\n",
    "  return Delta(conditions=random_sample(all_conditions, num_samples, random_state))\n",
    "\n",
    "# **** STATE WRAPPER FOR YOUR EXPERIMENTALIST ***\n",
    "@on_state()\n",
    "def custom_sample_on_state(experiment_data,\n",
    "                           models_bms,\n",
    "                           models_lr,\n",
    "                           models_polyr,\n",
    "                           all_conditions,\n",
    "                           num_samples=1,\n",
    "                           random_state=None):\n",
    "\n",
    "  conditions = sample(\n",
    "          all_conditions,\n",
    "          models = [models_bms[-1], models_lr[-1], models_polyr[-1]],\n",
    "          num = num_samples\n",
    "      )\n",
    "\n",
    "  return Delta(conditions=conditions)\n",
    "\n",
    "# state wrapper for synthetic experiment runner\n",
    "@on_state()\n",
    "def run_experiment_on_state(conditions, experiment_runner):\n",
    "  data = experiment_runner.run(conditions=conditions, added_noise=0.0)\n",
    "  return Delta(experiment_data=data)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# the following function is used to compute the model performance\n",
    "# on the validation set in terms of mean squared error\n",
    "def get_validation_MSE(validation_experiment_data, working_state):\n",
    "    ivs = [iv.name for iv in validation_experiment_data.variables.independent_variables]\n",
    "    dvs = [dv.name for dv in validation_experiment_data.variables.dependent_variables]\n",
    "    X = validation_experiment_data.experiment_data[ivs]\n",
    "    y = validation_experiment_data.experiment_data[dvs]\n",
    "\n",
    "    y_pred_bms = working_state.models_bms[-1].predict(X)\n",
    "    y_pred_lr = working_state.models_lr[-1].predict(X)\n",
    "    y_pred_polyr = working_state.models_polyr[-1].predict(X)\n",
    "\n",
    "    MSE_bms = ((y - y_pred_bms)**2).mean()[0]\n",
    "    MSE_lr = ((y - y_pred_lr)**2).mean()[0]\n",
    "    MSE_polyr = ((y - y_pred_polyr)**2).mean()[0]\n",
    "\n",
    "    min_MSE = min(MSE_bms, MSE_lr, MSE_polyr)\n",
    "\n",
    "    return min_MSE"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def run_simulation(num_cycles, num_conditions_per_cycle, num_initial_conditions, bms_epochs, experiment_runner, sim=0):\n",
    "\n",
    "  # VALIDATION STATE\n",
    "  # at every step of our discovery process, we will evaluate the performance\n",
    "  # of the theorist against the ground truth. Here, we will define the ground\n",
    "  # truth as a grid of data points sampled across the domain of the experimental\n",
    "  # design space. We will store this validation set in a separate validation states\n",
    "\n",
    "  # create AutoRA state for validation purposes\n",
    "  validation_conditions = CustomState(variables=experiment_runner.variables)\n",
    "  validation_experiment_data = CustomState(variables=experiment_runner.variables)\n",
    "\n",
    "  # our validation set will be consists of a grid of experiment conditions\n",
    "  # across the entire experimental design domain\n",
    "  validation_conditions = grid_pool_on_state(validation_conditions)\n",
    "  validation_experiment_data = grid_pool_on_state(validation_experiment_data)\n",
    "  validation_experiment_data = run_experiment_on_state(validation_experiment_data, experiment_runner=experiment_runner)\n",
    "\n",
    "\n",
    "  benchmark_MSE_log = list()\n",
    "  working_MSE_log = list()\n",
    "\n",
    "  # INITIAL STATE\n",
    "  # We begin our discovery experiment with randomly sampled data set for 10\n",
    "  # conditions. We will use the same state for each experimentalist method.\n",
    "\n",
    "  # create initial AutoRA state which we will use for our discovery experiments\n",
    "  initial_state = CustomState(variables=experiment_runner.variables)\n",
    "\n",
    "  # we will initiate our discovery process with 10 randomly sampled experiment conditions\n",
    "  initial_state = random_pool_on_state(initial_state,\n",
    "                                      num_samples=num_initial_conditions,\n",
    "                                      random_state = sim)\n",
    "\n",
    "  # we obtain the corresponding experiment data\n",
    "  initial_state = run_experiment_on_state(initial_state, experiment_runner=experiment_runner)\n",
    "\n",
    "  # initialize benchmark state for random experimentalist\n",
    "  benchmark_state = CustomState(**initial_state.__dict__)\n",
    "\n",
    "  # initialize working state for your custom experimentalist\n",
    "  working_state = CustomState(**initial_state.__dict__)\n",
    "\n",
    "  # for each discovery cycle\n",
    "  for cycle in range(num_cycles):\n",
    "\n",
    "    print(\"SIMULATION \" + str(sim)  + \" / DISCOVERY CYCLE \" + str(cycle))\n",
    "\n",
    "    # first, we fit a model to the data\n",
    "    print(\"Fitting models on benchmark state...\")\n",
    "    benchmark_state = theorists_on_state(benchmark_state, bms_epochs=bms_epochs)\n",
    "    print(\"Fitting models on working state...\")\n",
    "    working_state = theorists_on_state(working_state, bms_epochs=bms_epochs)\n",
    "\n",
    "    # now we can determine how well the models do on the validation set\n",
    "    benchmark_MSE = get_validation_MSE(validation_experiment_data, benchmark_state)\n",
    "    benchmark_MSE_log.append(benchmark_MSE)\n",
    "\n",
    "    working_MSE = get_validation_MSE(validation_experiment_data, working_state)\n",
    "    working_MSE_log.append(working_MSE)\n",
    "\n",
    "    # then we determine the next experiment condition\n",
    "    print(\"Sampling new experiment conditions...\")\n",
    "    benchmark_state = random_sample_on_state(benchmark_state,\n",
    "                                              all_conditions=validation_conditions.conditions,\n",
    "                                              num_samples=num_conditions_per_cycle)\n",
    "    working_state = custom_sample_on_state(working_state,\n",
    "                                            all_conditions=validation_conditions.conditions,\n",
    "                                          num_samples=num_conditions_per_cycle)\n",
    "\n",
    "    print(\"Obtaining observations...\")\n",
    "    # we obtain the corresponding experiment data\n",
    "    benchmark_state = run_experiment_on_state(benchmark_state, experiment_runner=experiment_runner)\n",
    "    working_state = run_experiment_on_state(working_state, experiment_runner=experiment_runner)\n",
    "\n",
    "  return benchmark_MSE_log, working_MSE_log, benchmark_state, working_state"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run Simulations"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Set Meta Parameters"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# meta parameters\n",
    "\n",
    "# DO NOT CHANGE THESE PARAMETERS\n",
    "num_cycles = 20\n",
    "num_conditions_per_cycle = 1\n",
    "num_initial_conditions = 1\n",
    "\n",
    "# YOU MAY CHANGE THESE PARAMETERS\n",
    "num_discovery_simulations = 10\n",
    "bms_epochs = 100 # Note, to speed things up, you can set bms_epochs = 10 or even bms_epochs = 1 (this will lead to poor performance of the BMS regressor but the other two theorists will still fit)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Single Run"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# setting experiment runner and theorist\n",
    "experiment_runner = task_switching()\n",
    "\n",
    "# run simulation\n",
    "benchmark_MSE_log, working_MSE_log, benchmark_state, working_state = run_simulation(num_cycles, num_conditions_per_cycle, num_initial_conditions, bms_epochs, experiment_runner)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# let's plot the benchmark_MSE_log and the working_MSE_log\n",
    "plt.plot(benchmark_MSE_log, label='benchmark_MSE_log')\n",
    "plt.plot(working_MSE_log, label='working_MSE_log')\n",
    "plt.xlabel('Sampled Data Points')\n",
    "plt.ylabel('MSE on Validation Set')\n",
    "plt.title('Single Discovery Simulation')\n",
    "plt.legend()\n",
    "\n",
    "# we can also investigate the final state more closely\n",
    "# for example, these are all the experimental data collected\n",
    "# under random sampling:\n",
    "print(benchmark_state.experiment_data)\n",
    "# and for your custom experimentalist\n",
    "print(working_state.experiment_data)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Averaging Over Multiple Runs"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# meta parameters\n",
    "\n",
    "# DO NOT CHANGE THESE PARAMETERS\n",
    "num_cycles = 20\n",
    "num_conditions_per_cycle = 1\n",
    "num_initial_conditions = 1\n",
    "num_discovery_simulations = 20\n",
    "bms_epochs = 100\n",
    "\n",
    "# setting experiment runner and theorist\n",
    "experiment_runner = task_switching()\n",
    "\n",
    "benchmark_MSE_plot_data = np.zeros([num_discovery_simulations, num_cycles])\n",
    "working_MSE_plot_data = np.zeros([num_discovery_simulations, num_cycles])\n",
    "\n",
    "for sim in range(num_discovery_simulations):\n",
    "  benchmark_MSE_log, working_MSE_log, benchmark_state, working_state = run_simulation(num_cycles, num_conditions_per_cycle, num_initial_conditions, bms_epochs, experiment_runner, sim)\n",
    "\n",
    "  benchmark_MSE_plot_data[sim, :] = benchmark_MSE_log\n",
    "  working_MSE_plot_data[sim, :] = working_MSE_log"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(np.sum(np.mean(working_MSE_plot_data, axis=0)))"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.mean(working_MSE_plot_data, axis=0)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
